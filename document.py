from xml.etree import ElementTree
from langchain_text_splitters import TokenTextSplitter
import os


class Document:
    def __init__(self, path: str, chunk_size: int = 1000):
        """
        :param path: path to the .xml generated by grobid or .txt file
        """
        if not os.path.exists(path):
            raise ValueError(f"File {path} does not exist")
        self.path = path
        self.chunk_size = chunk_size
        self.name = os.path.basename(path)
    
    def paragraph(self):
        raise NotImplementedError
    
    @staticmethod
    def _remove_special_char(string: str) -> str:
        return string.replace('â– ', '').replace('\t', ' ').strip()


class XmlDocument(Document):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
    
    def paragraph(self):
        """generator of paragraphs text in the document"""
        with open(self.path, "r", encoding='utf-8') as f:
            element = ElementTree.fromstring(f.read())
        paragraph = ""
        prefix = "{http://www.tei-c.org/ns/1.0}"
        # load title paragraph
        title = element.find(prefix + 'teiHeader').find(prefix + 'fileDesc').find(prefix + 'sourceDesc').find(prefix + 'biblStruct').find(prefix + 'analytic').find(prefix + 'title')
        if title is not None:
            paragraph += self._remove_special_char(title.text) + '\n'
        # load abstract paragraph
        abstract = element.find(prefix + 'teiHeader').find(prefix + 'profileDesc').find(prefix + 'abstract')
        if abstract is not None:
            for sentence in abstract.itertext():
                paragraph += self._remove_special_char(sentence)
        # load body paragraph
        for section in element.find(prefix + 'text').find(prefix + 'body').findall(prefix + 'div'):
            for sentence in section.itertext():
                if len(paragraph) >= self.chunk_size:
                    yield paragraph
                    paragraph = ""
                if not sentence.strip():
                    continue
                paragraph += self._remove_special_char(sentence)
                

class TxtDocument(Document):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.text_splitter = TokenTextSplitter(chunk_size=self.chunk_size, chunk_overlap=50)
    
    def paragraph(self):
        """generator of paragraphs text from txt file"""
        with open(self.path, "r", encoding='utf-8') as f:
            content = f.read()
        paragraphs = self.text_splitter.split_text(content)
        for p in paragraphs:
            yield p

if __name__ == '__main__':
    doc = TxtDocument("./ijsem/ijs.0.000497-0.txt", chunk_size=100)
    paragraph = doc.paragraph()
    print(next(paragraph))